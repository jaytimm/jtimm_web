---
title: corpus query and grammatical constructions
description: 'A demonstration of the use of a simple collection of functions from my R-package `corpuslingr`.'
author: ''
date: '2018-01-10'
slug: corpus-query-and-grammatical-constructions
tags: ['rstats','corpus ling', 'gramx']
output:
  blogdown::html_page:
    toc: yes
    df_print: paged
banner: banners/corpus_query.png
---

<link href="/rmarkdown-libs/pagedtable/css/pagedtable.css" rel="stylesheet" />
<script src="/rmarkdown-libs/pagedtable/js/pagedtable.js"></script>
<script src="/rmarkdown-libs/htmlwidgets/htmlwidgets.js"></script>
<script src="/rmarkdown-libs/jquery/jquery.min.js"></script>
<link href="/rmarkdown-libs/datatables-css/datatables-crosstalk.css" rel="stylesheet" />
<script src="/rmarkdown-libs/datatables-binding/datatables.js"></script>
<link href="/rmarkdown-libs/dt-core/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="/rmarkdown-libs/dt-core/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="/rmarkdown-libs/dt-core/js/jquery.dataTables.min.js"></script>
<link href="/rmarkdown-libs/crosstalk/css/crosstalk.css" rel="stylesheet" />
<script src="/rmarkdown-libs/crosstalk/js/crosstalk.min.js"></script>

<div id="TOC">
<ul>
<li><a href="#search-syntax">Search syntax</a></li>
<li><a href="#corpus-search">Corpus search</a></li>
<li><a href="#search-summary">Search summary</a></li>
<li><a href="#kwic-bow">KWIC &amp; BOW</a></li>
<li><a href="#summary-and-shiny">Summary and shiny</a></li>
</ul>
</div>

<p>This post demonstrates the use of a simple collection of functions from my R-package <code>corpuslingr</code>. Functions streamline two sets of corpus linguistics tasks:</p>
<ul>
<li>annotated corpus search of grammatical constructions and complex lexical patterns in context, and</li>
<li>detailed summary and aggregation of corpus search results.</li>
</ul>
<p>While still in development, the package should be useful to linguists and digital humanists interested in having <a href="https://corpus.byu.edu/">BYU corpora</a>-like search &amp; summary functionality when working with (moderately-sized) personal corpora, as well as researchers interested in performing finer-grained, more qualitative analyses of language use and variation in context. The package is available for download at <a href="https://github.com/jaytimm">my github site</a>.</p>
<pre class="r"><code>library(tidyverse)
library(corpuslingr) #devtools::install_github(&quot;jaytimm/corpuslingr&quot;)
library(corpusdatr) #devtools::install_github(&quot;jaytimm/corpusdatr&quot;)</code></pre>
<div id="search-syntax" class="section level2">
<h2>Search syntax</h2>
<p>Under the hood, <code>corpuslingr</code> search is regex-based &amp; tuple-based — akin to the <code>RegexpParser</code> function in Python’s Natural Language Toolkit (NLTK) — which facilitates search of grammatical and lexical patterns comprised of:</p>
<ul>
<li>different types of elements (eg, form, lemma, or part-of-speech),</li>
<li>contiguous and/or non-contiguous elements,</li>
<li>positionally fixed and/or free (ie, optional) elements.</li>
</ul>
<p>Regex character matching is streamlined with a simple “corpus querying language” modeled after the more intuitive and transparent syntax used in the online BYU suite of English corpora. This allows for convenient specification of search patterns comprised of form, lemma, &amp; pos, with all of the functionality of regex metacharacters and repetition quantifiers.</p>
<p>Example searches &amp; syntax are presented below, which load with the package as <code>clr_ref_search_egs</code>. A full list of part-of-speech codes can be viewed <a href="https://github.com/jaytimm/corpuslingr/blob/master/data-raw/clr_ref_pos_codes.csv">here</a>, or via <code>clr_ref_pos_codes</code>.</p>
<p>
<h4>
example search syntax
</h4>
</p>
<div id="htmlwidget-1" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-1">{"x":{"filter":"none","data":[["Simple form search","Simple lemma search","Lemma with POS search","Simple phrasal search","Phrasal search - POS/form","Phrasal search inc noun phrase","Phrasal search inc noun phrase","Suffix search","Infix search","Optional search w/ parens and ?","Multiple term search w parens and |","Multiple term search w parens and |","Indeterminate wildcard search w brackets and min/max","Multiple optional search"],["lime","DRINK","BARK~VERB","in the long run","ADJ and ADJ","VERB NPHR into VBG","VERB PRP$ way PREP NPHR","\\*tion","\\*break\\*","MD (NEG)? HAVE been","PRON (HOPE| WISH| DESIRE)","House (Republicans| Democrats)","NPHR BE (\\*){1,4} ADJ","(President)? (Bill)? Clinton"],["lime","drinks, drank, drinking","barked, barking","in the long run","happy and healthy, political and economical","trick someone into believing","make its way through the Senate","defenestration, nation, retaliation","breakable, heartbreaking","should have been, might not have been","He hoped, they wish","House Republicans, House Democrats","He was very, very happy; I'm not sure","Clinton, President Clinton, Bill Clinton"]],"container":"<table class=\"cell-border stripe\">\n  <thead>\n    <tr>\n      <th>type<\/th>\n      <th>search_syntax<\/th>\n      <th>example<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"pageLength":14,"dom":"t","order":[],"autoWidth":false,"orderClasses":false,"lengthMenu":[10,14,25,50,100],"rowCallback":"function(row, data) {\nvar value=data[0]; $(this.api().cell(row, 0).node()).css({'font-size':'85%'});\nvar value=data[1]; $(this.api().cell(row, 1).node()).css({'font-size':'85%'});\nvar value=data[2]; $(this.api().cell(row, 2).node()).css({'font-size':'85%'});\n}"}},"evals":["options.rowCallback"],"jsHooks":[]}</script>
</div>
<div id="corpus-search" class="section level2">
<h2>Corpus search</h2>
<p>For demo purposes, we use the <code>cdr_slate_ann</code> corpus from my <code>corpusdatr</code> package. A simple description of the corpus is available <a href="https://github.com/jaytimm/corpusdatr#slate-corpus">here</a>. Using the <code>corpuslingr::clr_set_corpus</code> function (which builds tuples and sets character onsets/offsets), we ready the corpus for search.</p>
<pre class="r"><code>slate &lt;- corpusdatr::cdr_slate_ann %&gt;% 
  corpuslingr::clr_set_corpus()</code></pre>
<p>
<h4>
SIMPLE SEARCH
</h4>
</p>
<p>The <code>clr_search_gramx()</code> function returns instantiations of a search pattern without context. It is for quick search. The function returns search results as a single dataframe.</p>
<ul>
<li><em>ADJECTIVE and ADJECTIVE</em>, eg “happy and healthy”</li>
</ul>
<pre class="r"><code>search1 &lt;- &quot;ADJ and ADJ&quot;  </code></pre>
<pre class="r"><code>slate %&gt;%
  corpuslingr::clr_search_gramx(search=search1)%&gt;%
  select(doc_id,token,tag)%&gt;%
  head()</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["doc_id"],"name":[1],"type":["chr"],"align":["left"]},{"label":["token"],"name":[2],"type":["chr"],"align":["left"]},{"label":["tag"],"name":[3],"type":["chr"],"align":["left"]}],"data":[{"1":"1","2":"long-established and nonjudgmental","3":"JJ CC JJ"},{"1":"1","2":"quaint and archaic","3":"JJ CC JJ"},{"1":"1","2":"widespread and durable","3":"JJ CC JJ"},{"1":"2","2":"arbitrary and capricious","3":"JJ CC JJ"},{"1":"3","2":"national and international","3":"JJ CC JJ"},{"1":"3","2":"depressing and bleak","3":"JJ CC JJ"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>
<h4>
SEARCH IN CONTEXT
</h4>
</p>
<p>The <code>clr_search_context()</code> function builds on <code>clr_search_gramx()</code> by adding surrounding context to the search phrase. Search windows can be specified using the LW/RW parameters. Function output includes a list of two data frames.</p>
<p>The first, <code>BOW</code>, presents results in a long format, which can be used to build word embeddings, for example. The second, <code>KWIC</code>, presents results with the surrounding context rebuilt in more or less a KWIC fashion. Both data frames serve as intermediary data structures for subsequent analyses.</p>
<ul>
<li><em>VERB PRP$ way PREP NPHR</em>, eg “make its way through the Senate”</li>
</ul>
<p>Per CQL above, <code>NPHR</code> can be used as a generic noun phrase search.</p>
<pre class="r"><code>search2 &lt;- &quot;VERB PRP$ way (through| into) NPHR&quot; </code></pre>
<pre class="r"><code>searchResults &lt;- slate %&gt;%
  corpuslingr::clr_search_context(search=search2, LW=5, RW = 5)</code></pre>
<p><code>KWIC</code> object:</p>
<pre class="r"><code>searchResults$KWIC %&gt;% head() %&gt;% select(-eg)</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["doc_id"],"name":[1],"type":["chr"],"align":["left"]},{"label":["lemma"],"name":[2],"type":["chr"],"align":["left"]},{"label":["tag"],"name":[3],"type":["chr"],"align":["left"]},{"label":["pos"],"name":[4],"type":["chr"],"align":["left"]},{"label":["aContext"],"name":[5],"type":["chr"],"align":["left"]},{"label":["token"],"name":[6],"type":["chr"],"align":["left"]},{"label":["zContext"],"name":[7],"type":["chr"],"align":["left"]}],"data":[{"1":"105","2":"munch his way through ream","3":"VBZ PRP$ NN IN NNS","4":"VERB ADJ NOUN ADP NOUN","5":". Schwarzenegger slowly and methodically","6":"munches his way through reams","7":"of cardboard zingers . \""},{"1":"142","2":"spend his way into 2 place","3":"VBD PRP$ NN IN JJ NN","4":"VERB ADJ NOUN ADP ADJ NOUN","5":"other candidates packing . Forbes","6":"spent his way into second place","7":". Dole is once again"},{"1":"35","2":"threaten its way into dominance","3":"VB PRP$ NN IN NN","4":"VERB ADJ NOUN ADP NOUN","5":"systems market to bully and","6":"threaten its way into dominance","7":"over the browser market ."},{"1":"354","2":"plow his way through hundred","3":"VBZ PRP$ NN IN NNS","4":"VERB ADJ NOUN ADP NOUN","5":"are . But as he","6":"plows his way through hundreds","7":"of pages of witness statements"},{"1":"361","2":"force their way into a Phoenix home","3":"VBD PRP$ NN IN DT NNP NN","4":"VERB ADJ NOUN ADP DET PROPN NOUN","5":", five armed bounty hunters","6":"forced their way into a Phoenix home","7":", shooting and killing two"},{"1":"542","2":"muscle his way into the neighborhood number racket","3":"VBN PRP$ NN IN DT NN NNS NN","4":"VERB ADJ NOUN ADP DET NOUN NOUN NOUN","5":"Prohibition beer baron who has","6":"muscled his way into the neighborhood numbers racket","7":", shutting down competitors or"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p><code>BOW</code> object:</p>
<pre class="r"><code>searchResults$BOW %&gt;% head()</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["doc_id"],"name":[1],"type":["chr"],"align":["left"]},{"label":["eg"],"name":[2],"type":["int"],"align":["right"]},{"label":["searchToken"],"name":[3],"type":["chr"],"align":["left"]},{"label":["searchLemma"],"name":[4],"type":["chr"],"align":["left"]},{"label":["searchTag"],"name":[5],"type":["chr"],"align":["left"]},{"label":["searchPos"],"name":[6],"type":["chr"],"align":["left"]},{"label":["sentence_id"],"name":[7],"type":["int"],"align":["right"]},{"label":["token_id"],"name":[8],"type":["int"],"align":["right"]},{"label":["token"],"name":[9],"type":["chr"],"align":["left"]},{"label":["lemma"],"name":[10],"type":["chr"],"align":["left"]},{"label":["pos"],"name":[11],"type":["chr"],"align":["left"]},{"label":["tag"],"name":[12],"type":["chr"],"align":["left"]},{"label":["entity"],"name":[13],"type":["chr"],"align":["left"]},{"label":["tup"],"name":[14],"type":["chr"],"align":["left"]},{"label":["tupBeg"],"name":[15],"type":["dbl"],"align":["right"]},{"label":["tupEnd"],"name":[16],"type":["dbl"],"align":["right"]},{"label":["rw"],"name":[17],"type":["int"],"align":["right"]},{"label":["place"],"name":[18],"type":["fctr"],"align":["left"]}],"data":[{"1":"35","2":"1","3":"threaten its way into dominance","4":"threaten its way into dominance","5":"VB PRP$ NN IN NN","6":"VERB ADJ NOUN ADP NOUN","7":"22","8":"12","9":"systems","10":"system","11":"NOUN","12":"NNS","13":"","14":"<systems~system~NNS>","15":"6948","16":"6968","17":"443","18":"aContext"},{"1":"35","2":"1","3":"threaten its way into dominance","4":"threaten its way into dominance","5":"VB PRP$ NN IN NN","6":"VERB ADJ NOUN ADP NOUN","7":"22","8":"13","9":"market","10":"market","11":"NOUN","12":"NN","13":"","14":"<market~market~NN>","15":"6969","16":"6987","17":"444","18":"aContext"},{"1":"35","2":"1","3":"threaten its way into dominance","4":"threaten its way into dominance","5":"VB PRP$ NN IN NN","6":"VERB ADJ NOUN ADP NOUN","7":"22","8":"14","9":"to","10":"to","11":"PART","12":"TO","13":"","14":"<to~to~TO>","15":"6988","16":"6998","17":"445","18":"aContext"},{"1":"35","2":"1","3":"threaten its way into dominance","4":"threaten its way into dominance","5":"VB PRP$ NN IN NN","6":"VERB ADJ NOUN ADP NOUN","7":"22","8":"15","9":"bully","10":"bully","11":"VERB","12":"VB","13":"","14":"<bully~bully~VB>","15":"6999","16":"7015","17":"446","18":"aContext"},{"1":"35","2":"1","3":"threaten its way into dominance","4":"threaten its way into dominance","5":"VB PRP$ NN IN NN","6":"VERB ADJ NOUN ADP NOUN","7":"22","8":"16","9":"and","10":"and","11":"CCONJ","12":"CC","13":"","14":"<and~and~CC>","15":"7016","16":"7028","17":"447","18":"aContext"},{"1":"35","2":"1","3":"threaten its way into dominance","4":"threaten its way into dominance","5":"VB PRP$ NN IN NN","6":"VERB ADJ NOUN ADP NOUN","7":"22","8":"17","9":"threaten","10":"threaten","11":"VERB","12":"VB","13":"","14":"<threaten~threaten~VB>","15":"7029","16":"7051","17":"448","18":"token"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
</div>
<div id="search-summary" class="section level2">
<h2>Search summary</h2>
<p>The <code>clr_get_freq()</code> function enables quick aggregation of search results. It calculates token and text frequency for search terms, and allows the user to specify how to aggregate counts with the <code>agg_var</code> parameter.</p>
<ul>
<li><em>VERB up</em>, eg “pass up”</li>
</ul>
<pre class="r"><code>search3 &lt;- &quot;VERB up&quot;</code></pre>
<p>The figure below illustrates the top 20 instantiations of the grammatical construction <em>VERB up</em>.</p>
<pre class="r"><code>slate %&gt;%
  corpuslingr::clr_search_gramx(search=search3)%&gt;%
  corpuslingr::clr_get_freq(agg_var=c(&quot;lemma&quot;),toupper =TRUE) %&gt;%
  slice(1:20)%&gt;%
  ggplot(aes(x=reorder(lemma,txtf), y=txtf)) + 
    geom_col(width=.6, fill=&quot;steelblue&quot;) +  
    coord_flip()+
    labs(title=&quot;Top 20 instantiations of &#39;VERB up&#39; by frequency&quot;)</code></pre>
<p><img src="/post/2017-11-29-corpus-query-and-grammatical-constructions_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<p>Although search is quicker when searching for multiple search terms simultaneaously, in some cases it may be useful to treat multiple search terms distinctly using <code>lapply()</code>:</p>
<pre class="r"><code>search3a &lt;- c(&quot;VERB across&quot;,&quot;VERB through&quot;, &quot;VERB out&quot;, &quot;VERB down&quot;)</code></pre>
<pre class="r"><code>vb_prep &lt;- lapply(1:length(search3a), function(y) {
  corpuslingr::clr_search_gramx(corp=slate, search=search3a[y])%&gt;%
  corpuslingr::clr_get_freq(agg_var=c(&quot;lemma&quot;),toupper =TRUE) %&gt;%
  mutate(search = search3a[y])
  }) %&gt;%  bind_rows()</code></pre>
<p>Summary by search:</p>
<pre class="r"><code>vb_prep %&gt;%
  group_by(search) %&gt;%
  summarize(gramx_freq = sum(txtf), gramx_type = n())</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["search"],"name":[1],"type":["chr"],"align":["left"]},{"label":["gramx_freq"],"name":[2],"type":["int"],"align":["right"]},{"label":["gramx_type"],"name":[3],"type":["int"],"align":["right"]}],"data":[{"1":"VERB across","2":"82","3":"41"},{"1":"VERB down","2":"428","3":"130"},{"1":"VERB out","2":"1744","3":"292"},{"1":"VERB through","2":"283","3":"133"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p><br> Top 10 instantiations of each search pattern by search term: <img src="/post/2017-11-29-corpus-query-and-grammatical-constructions_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
</div>
<div id="kwic-bow" class="section level2">
<h2>KWIC &amp; BOW</h2>
<p>
<h4>
KEYWORD IN CONTEXT
</h4>
</p>
<p><code>clr_context_kwic()</code> is a super simple function that rebuilds search contexts from the output of <code>clr_search_context()</code>. The <code>include</code> parameter allows the user to add details about the search pattern, eg. part-of-speech, to the table. It works nicely with <code>DT</code> tables.</p>
<ul>
<li><em>VERB NOUNPHRASE into VERBING</em>, eg “trick someone into believing”</li>
</ul>
<pre class="r"><code>search4 &lt;- &quot;VERB NPHR into VBG&quot;  </code></pre>
<pre class="r"><code>slate %&gt;%
  corpuslingr::clr_search_context(search=search4, LW=10, RW = 10) %&gt;%
  corpuslingr::clr_context_kwic(include=c(&#39;doc_id&#39;)) %&gt;%
  DT::datatable(class = &#39;cell-border stripe&#39;, rownames = FALSE,width=&quot;100%&quot;, escape=FALSE)%&gt;%
    DT::formatStyle(c(1:2),fontSize = &#39;85%&#39;)</code></pre>
<div id="htmlwidget-2" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-2">{"x":{"filter":"none","data":[["15","19","33","68","85","103","167","263","299","319","329","344","410","410","413","427","439","454","532","542","551","608","639","649","685","699","710","714","718","752","755","782","951","951","969"],["the magic words , find the formula that will turn <mark> self-fulfilling pessimism into self-fulfilling <\/mark> optimism . But win or lose , the story is","For one , the relatively toothless post-1911 House of Lords <mark> lulled people into thinking <\/mark> it was a good idea to have a delaying or","but effectively , Bennett claimed that Walsh was trying to <mark> blackmail Weinberger into telling <\/mark> falsehoods about Ronald Reagan . Meanwhile , Bennett lobbied the",") The next time one of these yentas tries to <mark> goad you into dishing <\/mark> your soon-to-be-former mate , just smile and say , \"","from Chicago , Harvard , and Stanford . These worthies <mark> lured the red-ink-wary Dole into espousing <\/mark> an across-the-board 15 percent tax-rate cut that even the average","of eleventh-hour cash that the party high command is instead <mark> putting money into erasing <\/mark> party debt and the launch of Al Gore 's presidential","Some European papers seem to be trying to <mark> will Bill Clinton into sending <\/mark> ground troops to Kosovo . The Daily Telegraph of London","a $ 6.5-billion jet fighter . He thinks General Dynamics <mark> blackmailed the president into giving <\/mark> it the contract . Once again , though , he","Ally McBeal , there 's no one more adept at <mark> flinging herself into mortifying <\/mark> situations with masochistic relish . Thank heaven for the rustics","will be a charming rogue and great communicator who will <mark> dupe Israel into following <\/mark> his lead , and then will turn on the Jewish","that investors must not let the ease of mouse transactions <mark> goad them into trading <\/mark> too quickly or too often . In a front-pager headlined","of presidential elections , they developed a formidable ability to <mark> psyche themselves into believing <\/mark> that the fault lay elsewhere . When Jimmy Carter went","'s Women . Toobin then blasts Isikoff for trying to <mark> talk Tripp into cooperating <\/mark> with him . According to Tripp , Isikoff told her","it . In other words , he 's trying to <mark> talk a source into giving <\/mark> a story to him , and his employer . That","sell Seagram air time because they feared liquor ads would <mark> prod Congress into investigating <\/mark> the proliferation of beer ads on television . Millions of","a way of signaling status , even if we 've <mark> deluded ourselves into thinking <\/mark> it 's not . There is n't much room in","for Islamic anti-Americanism . Until it addresses its failure to <mark> pressure Israel into making <\/mark> concessions to legitimate Palestinian claims , and recognises that the","are fundamentally inexpensive , so you are n't going to <mark> lure many more people into seeing <\/mark> , say , Eyes Wide Shut by slashing the already","Citibank , or your Travelers agent will be able to <mark> badger you into getting <\/mark> a Citibank credit card after he 's done badgering you","Roth 's Schultz off against Garcia 's Luciano , effectively <mark> duping Luciano into slaying <\/mark> Schultz . In life , Schultz 's murder was ordered","\" approach \" but its redundancy and insubstantiality . By <mark> conning the media into reporting <\/mark> that he was \" defending his philosophy , \" Bush","\" hoping that American diplomacy backed by bomber squadrons will <mark> cow Saddam into accepting <\/mark> Annan 's terms . Bill Kristol ( This Week )","as if Joe 's guilt over Logan 's death has <mark> brought Parry into being <\/mark> . Why does n't Clarissa ever see Parry , if","censor is he ? Well , he did succeed in <mark> coercing Time Warner into selling <\/mark> its interest in the gangsta-rap heavy Interscope label -- only","The anti-bloat whiners would have you believe that Microsoft is <mark> coercing them into using <\/mark> our extralarded software products ! I call their bluff .","-- that a few invisible planes ca n't fix . <mark> Enticing us into believing <\/mark> that wars can be won with Futurama technology and without","was Hatch 's claim that he was the guy who <mark> talked Reagan into winning <\/mark> the Cold War . \" I was the one who","Starr does n't ask for blood sample , hopes to <mark> trick Clinton into thinking <\/mark> he 's in the clear . Initial test shows no","lifestyle reporters to the local malls to coerce unsuspecting randomly <mark> selected shoppers into speaking <\/mark> the exact same seasonal cliches that the people came up","colds . The cynical spin is that pharmaceutical companies have <mark> duped the public into believing <\/mark> that they have allergies and need drugs to fix them","as Glass who crack up deserve sympathy because the system <mark> pressures them into becoming <\/mark> stars before they are journeymen . Please . This explanation","was on a visit to Damascus . Perhaps that would <mark> embarrass him into retiring <\/mark> , having plumbed depths of behavior unworthy of a scout","to their partners . About the same time , they <mark> suborned an IRS agent into initiating <\/mark> criminal tax probes of Jordache 's owners , probes that","an in-house union to undermine those organizing efforts , and <mark> coercing workers into participating <\/mark> in an anti-union rally . It 's capitalism with an",". \" No one had to work very hard to <mark> talk Clinton into accepting <\/mark> yet another abridgment of individual freedom for the sake of"]],"container":"<table class=\"cell-border stripe\">\n  <thead>\n    <tr>\n      <th>doc_id<\/th>\n      <th>kwic<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"order":[],"autoWidth":false,"orderClasses":false,"rowCallback":"function(row, data) {\nvar value=data[0]; $(this.api().cell(row, 0).node()).css({'font-size':'85%'});\nvar value=data[1]; $(this.api().cell(row, 1).node()).css({'font-size':'85%'});\n}"}},"evals":["options.rowCallback"],"jsHooks":[]}</script>
<p>
<h4>
BAG OF WORDS
</h4>
</p>
<p>The <code>clr_context_bow()</code> function returns a co-occurrence vector for each search term based on the context window-size specified in <code>clr_search_context()</code>. Again, how features are counted can be specified using the <code>agg_var</code> parameter. Additionally, features included in the vector can be filtered to content words using the <code>content_only</code> parameter.</p>
<ul>
<li><em>Multiple search terms</em></li>
</ul>
<pre class="r"><code>search5 &lt;- c(&quot;Clinton&quot;, &quot;Lewinsky&quot;, &quot;Bradley&quot;, &quot;McCain&quot;, &quot;Milosevic&quot;, &quot;Starr&quot;,  &quot;Microsoft&quot;, &quot;Congress&quot;, &quot;China&quot;, &quot;Russia&quot;)</code></pre>
<p>Here we search for some prominent players of the late 90s (when articles in the <code>cdr_slate_ann</code> corpus were published), and plot the most frequent co-occurring features of each search term.</p>
<pre class="r"><code>co_occur &lt;- slate %&gt;%
  corpuslingr::clr_search_context(search=search5, LW=15, RW = 15)%&gt;%
  corpuslingr::clr_context_bow(content_only=TRUE, agg_var=c(&#39;searchLemma&#39;,&#39;lemma&#39;,&#39;pos&#39;))</code></pre>
<p>Plotting facets in <code>ggplot</code> is problematic when within-facet categories contain some overlap. We add a couple of hacks to address this.</p>
<pre class="r"><code>co_occur %&gt;%
  filter(pos==&quot;NOUN&quot;)%&gt;%
  arrange(searchLemma,cofreq)%&gt;%
  group_by(searchLemma)%&gt;%
  top_n(n=10,wt=jitter(cofreq))%&gt;%
  ungroup()%&gt;%
  #Hack1 to sort order within facet
  mutate(order = row_number(), lemma=factor(paste(order,lemma,sep=&quot;_&quot;), levels = paste(order, lemma, sep = &quot;_&quot;)))%&gt;%
  ggplot(aes(x=lemma, y=cofreq, fill=searchLemma)) + 
    geom_col(show.legend = FALSE) +  
    facet_wrap(~searchLemma, scales = &quot;free_y&quot;, ncol = 2) +
    scale_x_discrete(labels = function(x) gsub(&quot;^.*_&quot;, &quot;&quot;, x))+#Hack2 to modify labels
    theme_fivethirtyeight()+ scale_fill_stata() +
    theme(plot.title = element_text(size=13))+ 
    coord_flip()+
    labs(title=&quot;Co-occurrence frequencies for some late 20th century players&quot;)</code></pre>
<p><img src="/post/2017-11-29-corpus-query-and-grammatical-constructions_files/figure-html/unnamed-chunk-20-1.png" width="672" /></p>
</div>
<div id="summary-and-shiny" class="section level2">
<h2>Summary and shiny</h2>
<p>So, a quick demo of some <code>corpuslingr</code> functions for annotated corpus search &amp; summary of complex lexical-grammatical patterns in context.</p>
<p>I have built a Shiny app to search/explore the Slate Magazine corpus available <a href="https://jasontimm.shinyapps.io/corpuslingr_demo/">here</a>. Code for building the app is available <a href="https://github.com/jaytimm/shiny_corpuslingr">here</a>. Swapping out the Slate corpus for a personal one should be fairly straightforward, with the caveat that the annotated corpus needs to be set/“tuple-ized” using the <code>clr_set_corpus</code> function from <code>corpuslingr</code>.</p>
</div>
