---
title: media bias & shared news on Twitter
author: ''
date: '2021-01-29'
slug: media-bias
categories: []
tags: []
output:
  blogdown::html_page:
    toc: true
    toc_depth: 2
bibliography: biblio.bib
link-citations: yes
description: 'Methods for quantifying political bias of online news media'
banner: banners/url.png
---


## Introduction

This post provides a brief description of methods for quantifying political bias of online news media based on the media-sharing habits of US lawmakers on Twitter.  I have discussed this set of methods in [a previous post](https://www.jtimm.net/2018/11/03/twitter-political-ideology-and-the-115-us-senate/).  Here, the focus is on a more streamlined (and multi-threaded) approach to **resolving shortened URLs** via the `quicknews` package.  We also present unsupervised methods for visualizing media bias in two-dimensional space via tSNE, and compare results to the manually curated fact and bias checking online resource, [Media Bias/Fact Check](https://mediabiasfactcheck.com/) (MBFC), with some fairly nice results.


```{r message=FALSE, warning=FALSE}
library(tidyverse)
localdir <- '/home/jtimm/jt_work/GitHub/data_sets'
##  devtools::install_github("jaytimm/quicknews")
```




## Tweet-set

The tweet-set used here was accessed via the [GWU Library](https://tweetsets.library.gwu.edu/datasets), and subsequently "hydrated" using the [Hydrator](https://github.com/DocNow/hydrator) desktop application.  Tweets were generated by members of the 116th House from 3 Jan 2019 to 7 May 2020.  Subsequent analyses are based on a sample of 500 tweets/lawmaker containing shared URLs.


```{r message=FALSE, warning=FALSE}
setwd(localdir)
house_tweets <- readRDS('house116-sample-urls.rds') %>%
  filter(urls != '')
```


```{r eval=FALSE, include=FALSE}
length(unique(house_tweets$user_screen_name))
```



```{r eval=FALSE, include=FALSE}
## WORKFLOW DESCRIPTION -- tweets-ids retrieved from GWU -- with some url-focused filtering -- subsequently re-hydrated -- below: filter/sample GWU tweet-set; house/116/sample n=250; 

# setwd('/home/jtimm/Desktop')
# tweets <- read.csv('tweet-ids-001.csv')
# 
# house116 <- uspols::uspols_twitter_handles %>%
#   filter(account_type == 'office',
#          congress == 116,
#          chamber == 'House')
# 
# house_tweets <- tweets %>%
#   filter(toupper(user_screen_name) %in% house116$screen_name) %>%
#   arrange(user_screen_name) %>%
#   group_by(user_screen_name) %>%
#   slice(1:500) %>%
#   ungroup()%>%
#   select(user_screen_name, urls)
# 
# setwd('/home/jtimm/jt_work/GitHub/data_sets')
# saveRDS(house_tweets, 'house116-sample-urls.rds')
```



## Media bias data set

[Media Bias/Fact Check](https://mediabiasfactcheck.com/) is a fact-checking organization that classifies online news sources along two dimensions: (1) political bias and (2) factuality.  These two scores (for ~850 sources) have been extracted by @baly:2020:ACL2020, and made available in tabular format [here](https://github.com/ramybaly/News-Media-Reliability).


```{r message=FALSE, warning=FALSE}
setwd('/home/jtimm/jt_work/GitHub/packages/quicknews/data-raw')
## emnlp18 <- read.csv('emnlp18-corpus.tsv', sep = '\t')
acl2020 <- read.csv('acl2020-corpus.tsv', sep = '\t')
```



A sample of this data set is presented below.

```{r message=FALSE, warning=FALSE}
set.seed(221)
acl2020 %>%
  group_by(fact, bias) %>%
  sample_n(1) %>%
  # ungroup() %>%
  select(source_url_normalized, fact, bias) %>%
  # spread(bias, source_url_normalized) %>%
  knitr::kable()
```



## Resolving shortened URLs

The [quicknews](https://github.com/jaytimm/quicknews) package is a collection of tools for navigating the online news landscape; here, we detail a simple workflow for researchers to use for multi-threaded URL un-shortening.  As a three step process: (1) identify URLs that have been shortened via `qnews_clean_urls`, (2) split vector of URLs into multiple batches via `qnews_split_batches` for distribution across multiple cores, and (3) resolve shortened URLs via `qnews_unshorten_urls`.

```{r eval=FALSE, message=FALSE, warning=FALSE}
## step 1
shortened_urls <- quicknews::qnews_clean_urls(url = house_tweets$urls) %>%
  filter(is_short == 1) 

## step 2
batch_urls <- shortened_urls %>% quicknews::qnews_split_batches(n = 12)

## step 3
unshortened_urls <- parallel::mclapply(lapply(batch_urls, "[[", 1),
                                       quicknews::qnews_unshorten_urls,
                                       seconds = 10, 
                                       mc.cores = 12)

unshortened_urls1 <- data.table::rbindlist(unshortened_urls)
```


```{r include=FALSE, message=FALSE, warning=FALSE}
# setwd('/home/jtimm/jt_work/GitHub/data_sets')
# saveRDS(outs, 'with-unshort.rds')
setwd(localdir)
unshortened_urls1 <- readRDS('with-unshort.rds')
```




## Shared news media sources

Next, we update the original tweet-set with the resolved URLs from above; we also extract domain information from each shared link in our data set.

```{r message=FALSE, warning=FALSE}
full_tweets <- house_tweets %>%
  left_join(unshortened_urls1, by = c('urls' = 'short_url')) %>%
  mutate(long_url = ifelse(is.na(long_url), urls, long_url), 
         source = gsub('(http)(s)?(://)(www\\.)?', '', long_url),
         source = gsub('/.*$', '', source),
         user_screen_name = toupper(user_screen_name))  ###
```



The list below details some less useful domains that we can remove from the data frame of shared URLs.

```{r}
junks <-  c('facebook', 'lnkd.in',
            'twitter', 'youtube',
            'youtu\\.be', 'instagram',
            'twimg', 'tumblr',
            'google', 'medium',
            'vimeo', '\\.gov',
            'actblue\\.com', 'bit\\.ly',
            'ow\\.ly', 'timeout',
            'myemail', 'apple.news',
            'trib.al')

filt.tweets <- full_tweets %>%
  filter(!grepl(paste0(junks, collapse = '|'), long_url)) 
```




The table below summarizes some of the more frequently shared news media domains among lawmakers during the 116th congress.  For good measure, domains are ranked by `% coverage`, which is the percentage of lawmakers that have shared a news link from a given domain in our data set.  So, 94% (or 403/429) of House members shared content from [The Hill](https://thehill.com/), which compares to 49% for Fow News and only 15% for Breitbert.

```{r message=FALSE, warning=FALSE}
share.summary <- filt.tweets %>% 
  mutate(source = tolower(source)) %>%
  group_by(source) %>%
  summarize(n = n(), tweeters = length(unique(user_screen_name))) %>%
  ungroup() %>%
  mutate(cover = round(tweeters/429*100,1)) %>%
  #left_join(acl2020, by = c('source' = 'source_url_normalized')) %>%
  arrange(desc(tweeters)) %>%
  filter(tweeters > 10) 
```


```{r echo=FALSE}
share.summary %>%
  slice(1:10) %>%
  knitr::kable()
```




## Media bias & tSNE

### Build matrix 

To aggregate these data, we build a simple `domain-lawmaker matrix`, in which each domain/news organization is represented by the number of times each lawmaker has shared one of its news stories.   


```{r}
ft1 <- filt.tweets %>%
  group_by(user_screen_name, source) %>%
  count() %>%
  filter(source %in% share.summary$source) %>%
  tidytext::cast_sparse(row = 'source',
                        column = 'user_screen_name',
                        value = n)

ft2 <- as.matrix(ft1) #%>% Rtsne::normalize_input()
```



Matrix top-left::

```{r}
ft2[1:5, 1:5]
```



### TSNE

```{r}
set.seed(77) ## 9
tsne <- Rtsne::Rtsne(X = ft2, check_duplicates = FALSE)
tsne_clean <- data.frame(descriptor_name = rownames(ft1), tsne$Y) %>% 
  #mutate(screen_name = toupper(descriptor_name)) %>%
  left_join(acl2020, by = c('descriptor_name' = 'source_url_normalized')) %>%
  replace(is.na(.), 'x')
```



### Plot

Per figure below, the first dimension of the tSNE plot does a fairly nice job capturing differences in **bias classifications** as presented by [Media Bias/Fact Check](https://mediabiasfactcheck.com/), and results are generally intuitive.  Factors underlying variation along the second dimension, however, are less clear, and do not appear to be capturing **factuality** in this case. *Note: news organizations indicated by orange Xs are not included in the MB/FC data set.*


```{r fig.height=7, message=FALSE, warning=FALSE}
split_pal <- c('#3c811a', 
               '#395f81', '#9e5055',
               '#e37e00')

tsne_clean %>%
  ggplot(aes(X1, X2)) +
  geom_point(aes(col = bias, 
                 shape = fact),
             size = 3) +
  geom_text(aes(label = descriptor_name,
                col = bias,
                shape = fact), #
            size = 3, 
            check_overlap = TRUE) +
  theme_minimal() +
  theme(legend.position = "bottom") +
  scale_color_manual(values = split_pal) +
  xlab('Dimension 1') + ylab('Dimension 2')+ 
  labs(title = "Measuring political bias")
```




### Bias score distributions

```{r fig.height=6}
tsne_clean %>%
  ggplot() +
  geom_density(aes(X1, fill = bias),
               alpha = .4) +
  theme_minimal() +
  theme(legend.position = "bottom") +
  scale_fill_manual(values = split_pal) +
  ggtitle('Media bias scores by MB/FC bias classification')
```


## Resources





