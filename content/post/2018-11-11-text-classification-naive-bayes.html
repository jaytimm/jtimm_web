---
title: genre, text classification & naive bayes
description: 'Predicting text genre via a Naive Bayes classifier.'
author: ''
date: '2018-11-15'
slug: text-classification-naive-bayes
output:
  blogdown::html_page:
    toc: true
    toc_depth: 2
bibliography: biblio.bib
link-citations: yes
categories: []
tags: ['rstats', 'corpus-ling']
banner: banners/naivebayes.png
---

<script src="/rmarkdown-libs/htmlwidgets/htmlwidgets.js"></script>
<script src="/rmarkdown-libs/jquery/jquery.min.js"></script>
<link href="/rmarkdown-libs/datatables-css/datatables-crosstalk.css" rel="stylesheet" />
<script src="/rmarkdown-libs/datatables-binding/datatables.js"></script>
<link href="/rmarkdown-libs/dt-core/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="/rmarkdown-libs/dt-core/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="/rmarkdown-libs/dt-core/js/jquery.dataTables.min.js"></script>
<link href="/rmarkdown-libs/crosstalk/css/crosstalk.css" rel="stylesheet" />
<script src="/rmarkdown-libs/crosstalk/js/crosstalk.min.js"></script>

<div id="TOC">
<ul>
<li><a href="#building-a-historical-genre-based-corpus">Building a historical, genre-based corpus</a></li>
<li><a href="#building-a-naive-bayes-classifier">Building a Naive Bayes classifier</a></li>
<li><a href="#model-assessment-confusion-matrix">Model assessment &amp; confusion matrix</a></li>
<li><a href="#summary">Summary</a></li>
</ul>
</div>

<p>In this short post, we outline a Naive Bayes (NB) approach to genre-based text classification. First, we introduce &amp; describe a corpus derived from Google News’ RSS feed, which includes source and genre information. We then train, test &amp; evaluate the efficacy of an NB classifier applied to online news genres, with some fairly nice results. Here, we focus on the nuts/bolts of an R-based workflow, and leave discussion of theory &amp; Bayesian assumptions for another day.</p>
<pre class="r"><code>library(e1071)
library(caret)
library(corpuslingr)
library(tidyverse)
library(knitr)
#library(quicknews)#devtools::install_github(&quot;jaytimm/quicknews&quot;)</code></pre>
<div id="building-a-historical-genre-based-corpus" class="section level2">
<h2>Building a historical, genre-based corpus</h2>
<p>For demonstration purposes, I have built a fairly small corpus comprised of national news articles from Google News’ RSS feed. The corpus was built using my <code>quicknews</code> package, and assembled over the course of roughly one month (10/29/18 ~ 11/30/18).</p>
<p>Metadata were collected and articles scraped/annotated/aggregated to BOWs three times a day using the Windows task scheduler app. The R script used for corpus assembly (which should scale quite nicely to different/novel search types) is available <a href="https://github.com/jaytimm/quicknews/blob/master/task/build_qnews_corpus.R">here</a>.</p>
<p><strong>Metadata include</strong> the genre (as defined by Google News) &amp; domain name of article source; they also include the full/raw text of each article. The script above updates corpus (as a collection of BOWs) and metadata (as TIF) each time it is called by the task scheduler.</p>
<pre class="r"><code>setwd(local1)
qnews_tif &lt;- readRDS(&#39;qnews_eg_tif.rds&#39;)
qnews_bow &lt;- readRDS(&#39;qnews_eg_corpus.rds&#39;)%&gt;%
  mutate(doc_id = as.integer(doc_id)) %&gt;%
  left_join(qnews_tif %&gt;% select(doc_id, search))</code></pre>
<p>The table below summarizes the composition of our corpus in terms of genre. So, in roughly a month, we have assembled a ~6.9K text corpus comprised of ~4.2 million words. And fairly balanced as well from a genre perspective.</p>
<pre class="r"><code>qnews_bow %&gt;%
  filter(pos != &#39;PUNCT&#39;) %&gt;%
  group_by(search) %&gt;%
  summarize(tokens = sum(txtf),
            texts = length(unique(doc_id))) %&gt;%
  bind_rows(totals) %&gt;%
  DT::datatable(options = list(pageLength = 8,dom = &#39;t&#39;, scrollX = TRUE),
              rownames = FALSE, width=&quot;100%&quot;, escape=FALSE)</code></pre>
<div id="htmlwidget-1" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-1">{"x":{"filter":"none","data":[["topic_business","topic_entertainment","topic_health","topic_nation","topic_science","topic_technology","topic_world","TOTAL"],[480338,624332,607545,647611,556040,698772,660620,4275258],[814,1119,961,989,869,1170,1019,6941]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>search<\/th>\n      <th>tokens<\/th>\n      <th>texts<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"pageLength":8,"dom":"t","scrollX":true,"columnDefs":[{"className":"dt-right","targets":[1,2]}],"order":[],"autoWidth":false,"orderClasses":false,"lengthMenu":[8,10,25,50,100]}},"evals":[],"jsHooks":[]}</script>
<p>The plot below illustrates the growth of our corpus (by genre) over time.</p>
<pre class="r"><code>library(ggthemes)
qnews_bow %&gt;% 
  filter(pos != &#39;PUNCT&#39;) %&gt;%
  left_join(qnews_tif)  %&gt;%
  group_by(date, search) %&gt;% 
  summarize(tokens = sum(txtf)) %&gt;%
  group_by(search) %&gt;% 
  mutate(cum_tok = cumsum(tokens))%&gt;%
  filter(tokens &gt; 351) %&gt;%
  ggplot(aes(x=date, y=cum_tok, fill = search)) +
  geom_area(alpha = 0.75, color = &#39;gray&#39;) +
  ggthemes::scale_fill_economist()+
  theme(legend.position = &quot;bottom&quot;)+
  scale_y_continuous(labels = function(x) paste0(format(x/1000000), &#39; mil&#39;)) +
  labs(title = &quot;Composition of corpus (in tokens) over time&quot;)</code></pre>
<p><img src="/post/2018-11-11-text-classification-naive-bayes_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>Lastly, and largely for good measure, we take a quick look at corpus composition in terms of article sources. The plot below summarizes the top content generators within each genre as measured by article counts.</p>
<pre class="r"><code>qnews_tif %&gt;% 
  group_by(search, source) %&gt;% 
  summarize(count = n()) %&gt;%
  arrange(search,(count))%&gt;%
  top_n(n=7,wt=jitter(count))%&gt;%
  ungroup()%&gt;%
#Hack1 to sort order within facet
  mutate(order = row_number(), 
         source=factor(paste(order,source,sep=&quot;_&quot;), 
                      levels = paste(order, source, sep = &quot;_&quot;)))%&gt;%
  ggplot(aes(x=source, 
             y=count, 
             fill=search)) + 
  geom_col(show.legend = FALSE) +  
  facet_wrap(~search, scales = &quot;free_y&quot;, ncol = 2) +
#Hack2 to modify labels
  scale_x_discrete(labels = function(x) gsub(&quot;^.*_&quot;, &quot;&quot;, x))+
  ggthemes::theme_fivethirtyeight()+ 
  ggthemes::scale_fill_economist() +
  theme(plot.title = element_text(size=12))+ 
  coord_flip()+
  labs(title=&quot;Most frequent domains by Google News search topic&quot;)</code></pre>
<p><img src="/post/2018-11-11-text-classification-naive-bayes_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
</div>
<div id="building-a-naive-bayes-classifier" class="section level2">
<h2>Building a Naive Bayes classifier</h2>
<p>The table below illustrates the structure of our genre-based corpus (post some removal of stop words &amp; other less informative lemma types). The corpus, then, represents each constituent article as a bag-of-words (BOW).</p>
<pre class="r"><code>corpus_as_bow &lt;- qnews_bow %&gt;%  
  filter(pos %in% c(&#39;VERB&#39;, &#39;ADV&#39;,&#39;NOUN&#39;, &#39;ADJ&#39;, &#39;PROPN&#39;) &amp; 
           !lemma %in% c(toupper(corpuslingr::clr_ref_stops),&#39;&#39;) &amp; 
           grepl(&#39;^[A-Z]&#39;, lemma)) </code></pre>
<pre class="r"><code>corpus_as_bow %&gt;%
  head() %&gt;%
  DT::datatable(options = list(pageLength = 8,dom = &#39;t&#39;, scrollX = TRUE),
              rownames = FALSE, width=&quot;100%&quot;, escape=FALSE)</code></pre>
<div id="htmlwidget-2" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-2">{"x":{"filter":"none","data":[[1,1,1,1,1,1],["VOTE","JUST","PEOPLE","REALLY","ELECTION","VOTED"],["VOTE","JUST","PEOPLE","REALLY","ELECTION","VOTE"],["VB","RB","NNS","RB","NN","VBN"],["VERB","ADV","NOUN","ADV","NOUN","VERB"],[30,25,18,15,13,13],["topic_nation","topic_nation","topic_nation","topic_nation","topic_nation","topic_nation"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>doc_id<\/th>\n      <th>token<\/th>\n      <th>lemma<\/th>\n      <th>tag<\/th>\n      <th>pos<\/th>\n      <th>txtf<\/th>\n      <th>search<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"pageLength":8,"dom":"t","scrollX":true,"columnDefs":[{"className":"dt-right","targets":[0,5]}],"order":[],"autoWidth":false,"orderClasses":false,"lengthMenu":[8,10,25,50,100]}},"evals":[],"jsHooks":[]}</script>
<p>To build a Naive Bayes classifier, we first need to transform our BOW corpus into a document-term matrix. The two structures are functionally equivalent; the latter is simply a “wide” rendition of the former.</p>
<p>In addition to this basic transformation, the pipe below (1) excludes superfrequent/ infrequent terms from the matrix based on document frequencies, and (2) normalizes each document vector to account for variation in document length (— smarter approaches exist).</p>
<pre class="r"><code>set.seed(99)
corpus_as_dtm &lt;- corpus_as_bow %&gt;%
  group_by(doc_id, search, lemma) %&gt;%
  summarize(n=n()) %&gt;%
  group_by(lemma) %&gt;%
  mutate(docf = length(unique(doc_id))) %&gt;%
  ungroup() %&gt;%
  mutate(docf = docf/length(unique(doc_id))) %&gt;%
  filter(docf &gt; .02 &amp; docf &lt; .35) %&gt;% #Filter infrequent/super-frequent.
  select(-docf) %&gt;%
  group_by(doc_id) %&gt;%
  mutate(n = n/sqrt(sum(n^2))) %&gt;% #Doc freqs as unit vector
  spread(lemma,n) %&gt;%
  replace(., is.na(.), 0)%&gt;%
  ungroup() %&gt;%
  mutate(search = as.factor(search))</code></pre>
<p>Using the <code>caret</code> package, then, we divide the above matrix into a training set (as 70% of full data set) and a test set (as 30%). The <code>createDataPartition</code> function conveniently creates two equally proportioned samples.</p>
<pre class="r"><code>set.seed(99)
trainIndex &lt;- caret::createDataPartition(corpus_as_dtm$search, p=0.7)$Resample1
train_data &lt;- corpus_as_dtm[trainIndex, ]
test_data &lt;- corpus_as_dtm[-trainIndex, ] #Demo distributions.</code></pre>
<p>With the <code>naiveBayes</code> function from the <code>e1071</code> package, we build our Naive Bayes classifier based on the training portion of the document-term matrix.</p>
<pre class="r"><code>classifier &lt;- e1071::naiveBayes(
  as.matrix(train_data[,3:ncol(train_data)]),
                    train_data$search,
                    laplace = 0.5) </code></pre>
<p>Then we implement the classifier on the test portion of the document-term matrix.</p>
<pre class="r"><code>test_predicted &lt;- 
  predict(classifier,
          as.matrix(test_data[,3:ncol(test_data)]))</code></pre>
<p>Output contains a vector of genre predictions for each text in the test data set. eg:</p>
<pre class="r"><code>head(test_predicted)</code></pre>
<pre><code>## [1] topic_nation  topic_world   topic_health  topic_health  topic_science
## [6] topic_science
## 7 Levels: topic_business topic_entertainment ... topic_world</code></pre>
</div>
<div id="model-assessment-confusion-matrix" class="section level2">
<h2>Model assessment &amp; confusion matrix</h2>
<p>So, to get a sense of classifier efficacy in identifying the genre of a given article posted on Google News, we calculate a cross-tab of observed &amp; predicted genres via the <code>confusionMatrix</code> function from <code>caret</code>.</p>
<pre class="r"><code>cfm &lt;- caret::confusionMatrix(data = test_predicted,
                              test_data$search)</code></pre>
<p><strong>Overall fitness statistics</strong> of our model can be accessed via the <code>overall</code> element from the list of outputs generated by the <code>confusionMatrix</code> function. So, classifier accuracy is quite good at ~ 80%. I am sure this is not at gold standard levels; however, seemingly alright for a simple lemma-based approach to text classification.</p>
<pre class="r"><code>cfm$overall</code></pre>
<pre><code>##       Accuracy          Kappa  AccuracyLower  AccuracyUpper   AccuracyNull 
##   0.8056758057   0.7726217922   0.7880007629   0.8224845042   0.1688311688 
## AccuracyPValue  McnemarPValue 
##   0.0000000000   0.0001735602</code></pre>
<p>Lastly, we visualize the confusion matrix based on the <code>table</code> element of output as a tile plot below. Tiles in the most prominent shade of blue reflect correct classifications.</p>
<pre class="r"><code>ggplot(data = as.data.frame(cfm$table) ,
           aes(x = Reference, y = Prediction)) +
    geom_tile(aes(fill = log(Freq)), colour = &quot;white&quot;) +
    scale_fill_gradient(low = &quot;white&quot;, high = &quot;steelblue&quot;) +
    geom_text(aes(x = Reference, y = Prediction, label = Freq)) +
    theme(legend.position = &quot;none&quot;,
          axis.text.x=element_text(angle=45,hjust=1)) + 
    labs(title=&quot;Confusion Matrix&quot;)</code></pre>
<p><img src="/post/2018-11-11-text-classification-naive-bayes_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<p>Output from the <code>confusionMatrix</code> function also includes a host of model diagnostics. The table below summarizes some of the more common diagnostics by genre, including <em>sensitivity</em> (1 - proportion of false negatives), <em>specificity</em> (1 - proportion of false positives), and the average of the two, <em>balanced accuracy</em>.</p>
<pre class="r"><code>cfm$byClass %&gt;% data.frame() %&gt;%
  select (Sensitivity, Specificity, Balanced.Accuracy) %&gt;%
  rownames_to_column(var = &#39;topic&#39;) %&gt;%
  mutate(topic = gsub(&#39;Class: &#39;,&#39;&#39;, topic)) %&gt;%
  mutate_if(is.numeric, round, 2) %&gt;%
  DT::datatable(options = list(pageLength = 7,dom = &#39;t&#39;, scrollX = TRUE),
              rownames = FALSE, width=&quot;100%&quot;, escape=FALSE) </code></pre>
<div id="htmlwidget-3" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-3">{"x":{"filter":"none","data":[["topic_business","topic_entertainment","topic_health","topic_nation","topic_science","topic_technology","topic_world"],[0.55,0.85,0.89,0.79,0.88,0.85,0.78],[0.97,0.97,0.98,0.96,0.97,0.97,0.97],[0.76,0.91,0.93,0.88,0.93,0.91,0.87]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>topic<\/th>\n      <th>Sensitivity<\/th>\n      <th>Specificity<\/th>\n      <th>Balanced.Accuracy<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"pageLength":7,"dom":"t","scrollX":true,"columnDefs":[{"className":"dt-right","targets":[1,2,3]}],"order":[],"autoWidth":false,"orderClasses":false,"lengthMenu":[7,10,25,50,100]}},"evals":[],"jsHooks":[]}</script>
</div>
<div id="summary" class="section level2">
<h2>Summary</h2>
<p>So, a super-quick code-through for building a fairly simple Naive Bayes classifier for genre-based text classification. Largely an excuse on my end to collate some thoughts &amp; resources, and to have a resource to point to (which seems to be lacking re NB text classification in R). Cheers.</p>
</div>
