---
title: genre, text classification & naive bayes
description: 'Predicting text genre via a Naive Bayes classifier.'
author: ''
date: '2018-11-15'
slug: text-classification-naive-bayes
output:
  blogdown::html_page:
    toc: true
    toc_depth: 2
bibliography: biblio.bib
link-citations: yes
categories: []
tags: ['rstats', 'corpus-ling']
banner: banners/naivebayes.png
---


<div id="TOC">
<ul>
<li><a href="#building-a-historical-genre-based-corpus">Building a historical, genre-based corpus</a></li>
<li><a href="#building-a-naive-bayes-classifier">Building a Naive Bayes classifier</a></li>
<li><a href="#model-assessment-confusion-matrix">Model assessment &amp; confusion matrix</a></li>
<li><a href="#summary">Summary</a></li>
</ul>
</div>

<p>In this short post, we outline a Naive Bayes (NB) approach to genre-based text classification. First, we introduce &amp; describe a corpus derived from Google News’ RSS feed, which includes source and genre information. We then train, test &amp; evaluate the efficacy of an NB classifier applied to online news genres, with some fairly nice results. Here, we focus on the nuts/bolts of an R-based workflow, and leave discussion of theory &amp; Bayesian assumptions for another day.</p>
<pre class="r"><code>library(e1071)
library(caret)
library(tidyverse)
library(knitr)
#library(quicknews)#devtools::install_github(&quot;jaytimm/quicknews&quot;)</code></pre>
<div id="building-a-historical-genre-based-corpus" class="section level2">
<h2>Building a historical, genre-based corpus</h2>
<p>For demonstration purposes, I have built a fairly small corpus comprised of national news articles from Google News’ RSS feed. The corpus (as TIF) was built using my <code>quicknews</code> package, and assembled over the course of roughly one month (10/29/18 ~ 11/30/18). Article text &amp; metadata were scraped/collected three times a day using the Windows task scheduler app. The R script used for corpus assembly (which should scale quite nicely to different/novel search types) is available <a href="https://github.com/jaytimm/quicknews/blob/master/task/build_qnews_corpus.R">here</a>.</p>
<pre class="r"><code>setwd(local1)
qnews_tif &lt;- readRDS(&#39;qnews_eg_tif.rds&#39;) %&gt;%
  mutate(length = lengths(gregexpr(&quot;\\W+&quot;, text)) + 1)</code></pre>
<p><strong>Metadata include</strong> the genre (as defined by Google News) &amp; domain name of article source.</p>
<pre class="r"><code>colnames(qnews_tif)</code></pre>
<pre><code>##  [1] &quot;doc_id&quot;  &quot;link&quot;    &quot;lang&quot;    &quot;country&quot; &quot;search&quot;  &quot;date&quot;    &quot;source&quot; 
##  [8] &quot;title&quot;   &quot;text&quot;    &quot;length&quot;</code></pre>
<p>The table below summarizes the composition of our corpus in terms of genre. So, in roughly a month, we have assembled a ~6.9K text corpus comprised of ~4.3 million words. And fairly balanced as well from a genre perspective.</p>
<pre class="r"><code>qnews_tif %&gt;%
  group_by(search) %&gt;%
  summarize(tokens = sum(length),
            texts = length(unique(doc_id))) %&gt;%
  janitor::adorn_totals(c(&#39;row&#39;)) %&gt;% 
  knitr::kable()</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">search</th>
<th align="right">tokens</th>
<th align="right">texts</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">topic_business</td>
<td align="right">488762</td>
<td align="right">814</td>
</tr>
<tr class="even">
<td align="left">topic_entertainment</td>
<td align="right">627014</td>
<td align="right">1119</td>
</tr>
<tr class="odd">
<td align="left">topic_health</td>
<td align="right">615731</td>
<td align="right">961</td>
</tr>
<tr class="even">
<td align="left">topic_nation</td>
<td align="right">654143</td>
<td align="right">989</td>
</tr>
<tr class="odd">
<td align="left">topic_science</td>
<td align="right">561797</td>
<td align="right">869</td>
</tr>
<tr class="even">
<td align="left">topic_technology</td>
<td align="right">697857</td>
<td align="right">1170</td>
</tr>
<tr class="odd">
<td align="left">topic_world</td>
<td align="right">663889</td>
<td align="right">1019</td>
</tr>
<tr class="even">
<td align="left">Total</td>
<td align="right">4309193</td>
<td align="right">6941</td>
</tr>
</tbody>
</table>
<p>The plot below illustrates the growth of our corpus (by genre) over time.</p>
<pre class="r"><code>qnews_tif  %&gt;%
  group_by(date, search) %&gt;% 
  summarize(tokens = sum(length)) %&gt;%
  group_by(search) %&gt;% 
  mutate(cum_tok = cumsum(tokens))%&gt;%
  filter(tokens &gt; 360) %&gt;%
  
  ggplot(aes(x=date, y=cum_tok, fill = search)) +
  geom_area(alpha = 0.75, color = &#39;gray&#39;) +
  ggthemes::scale_fill_economist()+
  theme(legend.position = &quot;bottom&quot;)+
  scale_y_continuous(labels = function(x) paste0(format(x/1000000), &#39; mil&#39;)) +
  labs(title = &quot;Composition of corpus (in tokens) over time&quot;)</code></pre>
<p><img src="/post/2018-11-11-text-classification-naive-bayes_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>Lastly, and largely for good measure, we take a quick look at corpus composition in terms of article sources. The plot below summarizes the top content generators within each genre as measured by article counts.</p>
<pre class="r"><code>qnews_tif %&gt;% 
  group_by(search, source) %&gt;% 
  summarize(count = n()) %&gt;%
  arrange(search,(count))%&gt;%
  top_n(n=7,wt=jitter(count))%&gt;%
  ungroup()%&gt;%
#Hack1 to sort order within facet
  mutate(order = row_number(), 
         source=factor(paste(order,source,sep=&quot;_&quot;), 
                      levels = paste(order, source, sep = &quot;_&quot;)))%&gt;%
  ggplot(aes(x=source, 
             y=count, 
             fill=search)) + 
  geom_col(show.legend = FALSE) +  
  facet_wrap(~search, scales = &quot;free_y&quot;, ncol = 2) +
#Hack2 to modify labels
  scale_x_discrete(labels = function(x) gsub(&quot;^.*_&quot;, &quot;&quot;, x))+
  ggthemes::theme_fivethirtyeight()+ 
  ggthemes::scale_fill_economist() +
  theme(plot.title = element_text(size=12))+ 
  coord_flip()+
  labs(title=&quot;Most frequent domains by Google News search topic&quot;)</code></pre>
<p><img src="/post/2018-11-11-text-classification-naive-bayes_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
</div>
<div id="building-a-naive-bayes-classifier" class="section level2">
<h2>Building a Naive Bayes classifier</h2>
<p>To build a Naive Bayes classifier via <code>caret</code>, we first need to transform the tif corpus to a document-term matrix (DTM). Here, we work within the <code>text2vec</code> framework (see vignette <a href="http://text2vec.org/">here</a>). Document vectors are L1-normalized and transformed via TF-IDF. Note that there are any number of other ways to transform a tif corpus to a DTM. Despite some idiosyncratic syntax, <code>text2vec</code> is super-quick &amp; super-flexible, and likely a bit overkill here.</p>
<pre class="r"><code>t2v_corp &lt;-  text2vec::itoken(qnews_tif$text, 
                              preprocessor = tolower, 
                              tokenizer = text2vec::word_tokenizer, 
                              ids = qnews_tif$doc_id)

vocab &lt;- text2vec::create_vocabulary(t2v_corp, 
                                     stopwords = tm::stopwords()) %&gt;%
  text2vec::prune_vocabulary(doc_proportion_min = .01,
                             doc_proportion_max = .4) %&gt;%
  arrange(term)

dtm &lt;- text2vec::create_dtm(t2v_corp, 
                            text2vec::vocab_vectorizer(vocab))

model_tfidf = text2vec::TfIdf$new()
dtm &lt;- model_tfidf$fit_transform(dtm)</code></pre>
<p>Using the <code>caret</code> package, then, we divide the above matrix into a training set (as 70% of full data set) and a test set (as 30%). The <code>createDataPartition</code> function conveniently creates two equally proportioned samples.</p>
<pre class="r"><code>set.seed(99)
trainIndex &lt;- caret::createDataPartition(qnews_tif$search, p=0.7)$Resample1
train_data &lt;- dtm[trainIndex, ]
test_data &lt;- dtm[-trainIndex, ] #Demo distributions.</code></pre>
<p>With the <code>naiveBayes</code> function from the <code>e1071</code> package, we build our Naive Bayes classifier based on the training portion of the document-term matrix.</p>
<pre class="r"><code>qnews_tif$search &lt;- as.factor(qnews_tif$search)

classifier &lt;- e1071::naiveBayes(as.matrix(train_data), 
                                qnews_tif[trainIndex, ]$search, 
                                laplace = 0.5) </code></pre>
<p>Then we implement the classifier on the test portion of the document-term matrix.</p>
<pre class="r"><code>test_predicted &lt;- predict(classifier, as.matrix(test_data))</code></pre>
<p>Output contains a vector of genre predictions for each text in the test data set. eg:</p>
<pre class="r"><code>head(test_predicted)</code></pre>
<pre><code>## [1] topic_nation  topic_world   topic_health  topic_health  topic_science
## [6] topic_science
## 7 Levels: topic_business topic_entertainment ... topic_world</code></pre>
</div>
<div id="model-assessment-confusion-matrix" class="section level2">
<h2>Model assessment &amp; confusion matrix</h2>
<p>So, to get a sense of classifier efficacy in identifying the genre of a given article posted on Google News, we calculate a cross-tab of observed &amp; predicted genres via the <code>confusionMatrix</code> function from <code>caret</code>.</p>
<pre class="r"><code>cfm &lt;- caret::confusionMatrix(data = test_predicted, qnews_tif[-trainIndex, ]$search)</code></pre>
<p><strong>Overall fitness statistics</strong> of our model can be accessed via the <code>overall</code> element from the list of outputs generated by the <code>confusionMatrix</code> function. So, classifier accuracy is quite good at ~ 80%. I am sure this is not at gold standard levels; however, seemingly alright for a simple token-based approach to text classification.</p>
<pre class="r"><code>cfm$overall</code></pre>
<pre><code>##       Accuracy          Kappa  AccuracyLower  AccuracyUpper   AccuracyNull 
##   7.912458e-01   7.556156e-01   7.731304e-01   8.085361e-01   1.688312e-01 
## AccuracyPValue  McnemarPValue 
##   0.000000e+00   9.853986e-08</code></pre>
<p>Lastly, we visualize the confusion matrix based on the <code>table</code> element of output as a tile plot below. Tiles in the most prominent shade of blue reflect correct classifications.</p>
<pre class="r"><code>ggplot(data = as.data.frame(cfm$table) ,
           aes(x = Reference, y = Prediction)) +
    geom_tile(aes(fill = log(Freq)), 
              colour = &quot;white&quot;) +
    scale_fill_gradient(low = &quot;white&quot;, 
                        high = &quot;steelblue&quot;) +
    geom_text(aes(x = Reference, 
                  y = Prediction, 
                  label = Freq)) +
    theme(legend.position = &quot;none&quot;,
          axis.text.x=element_text(angle=45,
                                   hjust=1)) + 
    labs(title=&quot;Confusion Matrix&quot;)</code></pre>
<p><img src="/post/2018-11-11-text-classification-naive-bayes_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
<p>Output from the <code>confusionMatrix</code> function also includes a host of model diagnostics. The table below summarizes some of the more common diagnostics by genre, including <em>sensitivity</em> (1 - proportion of false negatives), <em>specificity</em> (1 - proportion of false positives), and the average of the two, <em>balanced accuracy</em>.</p>
<pre class="r"><code>cfm$byClass %&gt;% data.frame() %&gt;%
  select (Sensitivity, Specificity, Balanced.Accuracy) %&gt;%
  rownames_to_column(var = &#39;topic&#39;) %&gt;%
  mutate(topic = gsub(&#39;Class: &#39;,&#39;&#39;, topic)) %&gt;%
  mutate_if(is.numeric, round, 2) %&gt;% 
  knitr::kable() </code></pre>
<table>
<thead>
<tr class="header">
<th align="left">topic</th>
<th align="right">Sensitivity</th>
<th align="right">Specificity</th>
<th align="right">Balanced.Accuracy</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">topic_business</td>
<td align="right">0.50</td>
<td align="right">0.97</td>
<td align="right">0.74</td>
</tr>
<tr class="even">
<td align="left">topic_entertainment</td>
<td align="right">0.82</td>
<td align="right">0.97</td>
<td align="right">0.90</td>
</tr>
<tr class="odd">
<td align="left">topic_health</td>
<td align="right">0.90</td>
<td align="right">0.96</td>
<td align="right">0.93</td>
</tr>
<tr class="even">
<td align="left">topic_nation</td>
<td align="right">0.79</td>
<td align="right">0.95</td>
<td align="right">0.87</td>
</tr>
<tr class="odd">
<td align="left">topic_science</td>
<td align="right">0.85</td>
<td align="right">0.97</td>
<td align="right">0.91</td>
</tr>
<tr class="even">
<td align="left">topic_technology</td>
<td align="right">0.87</td>
<td align="right">0.96</td>
<td align="right">0.91</td>
</tr>
<tr class="odd">
<td align="left">topic_world</td>
<td align="right">0.75</td>
<td align="right">0.97</td>
<td align="right">0.86</td>
</tr>
</tbody>
</table>
</div>
<div id="summary" class="section level2">
<h2>Summary</h2>
<p>So, a super-quick code-through for building a fairly simple Naive Bayes classifier for genre-based text classification. Largely an excuse on my end to collate some thoughts &amp; resources, and to have a resource to point to (which seems to be lacking re NB text classification in R). Cheers.</p>
</div>
